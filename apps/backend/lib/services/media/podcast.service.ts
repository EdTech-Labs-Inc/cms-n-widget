import { openaiService } from '../external/openai.service';
import { elevenlabsService } from '../external/elevenlabs.service';
import { storageService } from '../core/storage.service';
import { aiTaggingService } from '../ai-tagging.service';
import { thumbnailService } from './thumbnail.service';
import { prisma } from '../../config/database';
import { PodcastTranscript, PodcastTranscriptSchema } from '@/types/schemas';
import ffmpeg from 'fluent-ffmpeg';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import z from 'zod';
import { logger } from '@repo/logging';

/**
 * Podcast Service - Generate multi-speaker podcast from articles
 *
 * Workflow:
 * 1. Generate podcast transcript (interviewer + guest format) with OpenAI
 * 2. Convert each segment to audio with different voices (ElevenLabs)
 * 3. Stitch audio segments together (FFmpeg)
 * 4. Generate word-level timings for interactive podcast
 * 5. Upload final podcast to storage
 */
export class PodcastService {
  /**
   * Generate podcast for an article
   */
  async generatePodcast(articleId: string, outputId: string, organizationId?: string): Promise<void> {
    try {
      // Update status to PROCESSING
      await prisma.podcastOutput.update({
        where: { id: outputId },
        data: { status: 'PROCESSING' },
      });

      // Get article content
      const article = await prisma.article.findUnique({
        where: { id: articleId },
        include: { submissions: { where: { podcastOutputs: { some: { id: outputId } } } } },
      });

      if (!article) {
        throw new Error('Article not found');
      }

      const submission = article.submissions[0];
      if (!submission) {
        throw new Error('Submission not found');
      }

      // Use organizationId from parameter or article
      const orgId = organizationId || article.organizationId;

      const languageToUse = submission.language || 'ENGLISH';
      logger.info('Generating podcast', {
        articleTitle: article.title,
        language: languageToUse
      });

      // Step 1: Generate podcast title using OpenAI
      const podcastTitle = await this.generatePodcastTitle(article.title, article.content, languageToUse);
      logger.info('Generated podcast title', { podcastTitle });

      // Step 1.5: Generate thumbnail for podcast
      let thumbnailUrl: string | null = null;
      try {
        thumbnailUrl = await thumbnailService.generateThumbnail(podcastTitle, 'podcast', outputId, orgId);
      } catch (error) {
        logger.warn('Failed to generate podcast thumbnail', {
          error: error instanceof Error ? error.message : error
        });
        // Continue without thumbnail - not critical
      }

      // Step 2: Generate podcast transcript (interviewer + guest format)
      const transcript = await this.generatePodcastTranscript(article.title, article.content, languageToUse);
      const segments = transcript.segments as Array<{ speaker: 'interviewer' | 'guest'; text: string }>;

      // Step 3: Generate audio for each segment with different voices
      const audioSegments = await this.generateSegmentAudio(segments, submission.id);

      // Step 4: Stitch audio segments together with FFmpeg
      const { finalAudioBuffer, totalDuration } = await this.stitchAudioSegments(audioSegments);

      // Step 5: Upload final podcast to storage (returns both CloudFront and S3 URLs)
      const uploadResult = await storageService.uploadAudio(
        finalAudioBuffer,
        submission.id,
        'podcast.mp3',
        orgId
      );

      // Step 6: Calculate segment timings
      const timedSegments = this.calculateSegmentTimings(audioSegments);

      // Step 7: Save to database (use CloudFront URL for user delivery)
      await prisma.podcastOutput.update({
        where: { id: outputId },
        data: {
          title: podcastTitle,
          thumbnailUrl: thumbnailUrl,
          transcript: JSON.stringify(segments),
          audioFileUrl: uploadResult.cloudfrontUrl,
          segments: timedSegments,
          duration: Math.ceil(totalDuration),
          // Note: wordTimings will be generated by interactive podcast service if needed
          status: 'COMPLETED',
        },
      });

      logger.info('Podcast generated successfully', { articleId });

      // Step 7: Auto-tag the podcast output (only for English)
      await aiTaggingService.tagPodcastOutput(outputId);
    } catch (error) {
      logger.error('Podcast Generation Error', {
        error: error instanceof Error ? error.message : error
      });

      await prisma.podcastOutput.update({
        where: { id: outputId },
        data: {
          status: 'FAILED',
          error: error instanceof Error ? error.message : 'Unknown error',
        },
      });

      throw error;
    }
  }

  /**
   * Generate an engaging podcast title using OpenAI
   */
  private async generatePodcastTitle(articleTitle: string, articleContent: string, language: string): Promise<string> {
    const languageMap: Record<string, string> = {
      ENGLISH: 'English',
      MARATHI: 'Marathi',
      HINDI: 'Hindi',
      BENGALI: 'Bengali',
    };
    const languageName = languageMap[language] || 'English';

    const prompt = `generate_podcast_title_prompt`;

    const title = await openaiService.generateText({
      prompt,
      systemPrompt: `generate_podcast_title_system_prompt`,
      temperature: 0.7,
      maxTokens: 50,
    });

    return title.trim();
  }

  /**
   * Generate podcast transcript with interviewer + guest format
   */
  private async generatePodcastTranscript(title: string, content: string, language: string) {
    const languageMap: Record<string, string> = {
      ENGLISH: 'English',
      MARATHI: 'Marathi',
      HINDI: 'Hindi',
      BENGALI: 'Bengali',
    };
    const languageName = languageMap[language] || 'English';

    const prompt = `generate_podcast_transcript_prompt`;

    const result = await openaiService.generateStructured({
      prompt,
      schema: PodcastTranscriptSchema,
      schemaName: 'PodcastTranscript',
      systemPrompt: `generate_podcast_transcript_system_prompt`,
      temperature: 0.8, // Higher creativity for natural conversation
    });

    return result as PodcastTranscript;
  }

  /**
   * Generate audio for each podcast segment with different voices
   * NOTE: Generates sequentially to avoid ElevenLabs concurrency limits (max 5)
   */
  private async generateSegmentAudio(
    segments: Array<{ speaker: 'interviewer' | 'guest'; text: string }>,
    submissionId: string
  ) {
    const interviewerVoice = elevenlabsService.getInterviewerVoiceId();
    const guestVoice = elevenlabsService.getGuestVoiceId();

    logger.info('Generating audio for podcast segments', { segmentCount: segments.length });

    const audioSegments = [];

    // Generate segments sequentially to avoid ElevenLabs rate limits
    for (let index = 0; index < segments.length; index++) {
      const segment = segments[index];
      const voiceId = segment.speaker === 'interviewer' ? interviewerVoice : guestVoice;

      logger.info('Generating segment audio', {
        segmentIndex: index + 1,
        totalSegments: segments.length,
        speaker: segment.speaker
      });

      // Generate audio
      const audioBuffer = await elevenlabsService.textToSpeech({
        text: segment.text,
        voiceId,
      });

      // Save to temp file for FFmpeg processing
      const tempDir = os.tmpdir();
      const tempFile = path.join(tempDir, `podcast_segment_${submissionId}_${index}.mp3`);
      await fs.writeFile(tempFile, audioBuffer);

      // Get audio duration
      const duration = await this.getAudioDuration(tempFile);

      audioSegments.push({
        speaker: segment.speaker,
        text: segment.text,
        tempFile,
        duration,
      });
    }

    logger.info('Generated audio segments', { count: audioSegments.length });
    return audioSegments;
  }

  /**
   * Stitch audio segments together using FFmpeg
   */
  private async stitchAudioSegments(
    segments: Array<{ tempFile: string; duration: number }>
  ): Promise<{ finalAudioBuffer: Buffer; totalDuration: number }> {
    return new Promise((resolve, reject) => {
      const processStitching = async () => {
        try {
          logger.info('Stitching audio segments', { segmentCount: segments.length });

          const tempDir = os.tmpdir();
          const outputFile = path.join(tempDir, `podcast_final_${Date.now()}.mp3`);

          // Create FFmpeg command
          let command = ffmpeg();

          // Add all input files
          segments.forEach((segment) => {
            command = command.input(segment.tempFile);
          });

          // Concatenate and output
          command
            .on('end', async () => {
              try {
                // Read final file
                const finalAudioBuffer = await fs.readFile(outputFile);

                // Calculate total duration
                const totalDuration = segments.reduce((sum, seg) => sum + seg.duration, 0);

                // Cleanup temp files
                await Promise.all([
                  ...segments.map((seg) => fs.unlink(seg.tempFile).catch(() => {})),
                  fs.unlink(outputFile).catch(() => {}),
                ]);

                resolve({ finalAudioBuffer, totalDuration });
              } catch (error) {
                reject(error);
              }
            })
            .on('error', (error) => {
              reject(new Error(`FFmpeg error: ${error.message}`));
            })
            .mergeToFile(outputFile, tempDir);
        } catch (error) {
          reject(error);
        }
      };

      processStitching();
    });
  }

  /**
   * Get audio duration from file using FFmpeg
   */
  private getAudioDuration(filePath: string): Promise<number> {
    return new Promise((resolve, reject) => {
      ffmpeg.ffprobe(filePath, (err, metadata) => {
        if (err) {
          reject(err);
        } else {
          const duration = metadata.format.duration || 0;
          resolve(duration);
        }
      });
    });
  }

  /**
   * Calculate segment timings based on durations
   */
  private calculateSegmentTimings(
    segments: Array<{ speaker: 'interviewer' | 'guest'; text: string; duration: number }>
  ) {
    let currentTime = 0;
    return segments.map((segment) => {
      const startTime = currentTime;
      const endTime = currentTime + segment.duration;
      currentTime = endTime;

      return {
        speaker: segment.speaker,
        text: segment.text,
        startTime: Math.floor(startTime),
        endTime: Math.floor(endTime),
      };
    });
  }

  /**
   * Regenerate podcast with edited transcript
   * Re-generates audio with the updated transcript segments
   */
  async regeneratePodcast(podcastOutputId: string): Promise<void> {
    try {
      logger.info('Regenerating podcast', { podcastOutputId });

      // Update status to PROCESSING
      await prisma.podcastOutput.update({
        where: { id: podcastOutputId },
        data: { status: 'PROCESSING', error: null },
      });

      // Get the podcast output with its transcript
      const podcastOutput = await prisma.podcastOutput.findUnique({
        where: { id: podcastOutputId },
        include: {
          submission: {
            include: {
              article: true,
            },
          },
        },
      });

      if (!podcastOutput) {
        throw new Error('Podcast output not found');
      }

      if (!podcastOutput.transcript) {
        throw new Error('No transcript available for regeneration');
      }

      logger.info('Using edited transcript for regeneration');

      // Parse the transcript
      const segments = JSON.parse(podcastOutput.transcript) as Array<{ speaker: 'interviewer' | 'guest'; text: string }>;

      // Regenerate audio for each segment with different voices
      const audioSegments = await this.generateSegmentAudio(segments, podcastOutput.submissionId);

      // Stitch audio segments together with FFmpeg
      const { finalAudioBuffer, totalDuration } = await this.stitchAudioSegments(audioSegments);

      // Upload final podcast to storage
      const uploadResult = await storageService.uploadAudio(
        finalAudioBuffer,
        podcastOutput.submissionId,
        'podcast.mp3'
      );

      // Calculate segment timings
      const timedSegments = this.calculateSegmentTimings(audioSegments);

      // Update to database with new audio
      await prisma.podcastOutput.update({
        where: { id: podcastOutputId },
        data: {
          audioFileUrl: uploadResult.cloudfrontUrl,
          segments: timedSegments,
          duration: Math.ceil(totalDuration),
          status: 'COMPLETED',
        },
      });

      logger.info('Podcast regenerated successfully', { podcastOutputId });
    } catch (error) {
      logger.error('Podcast Regeneration Error', {
        error: error instanceof Error ? error.message : error
      });

      await prisma.podcastOutput.update({
        where: { id: podcastOutputId },
        data: {
          status: 'FAILED',
          error: error instanceof Error ? error.message : 'Unknown error',
        },
      });

      throw error;
    }
  }
}

// Singleton instance
export const podcastService = new PodcastService();
